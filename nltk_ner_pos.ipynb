{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make uitls/text.ipynb avaible\n",
    "%run utils/text.ipynb\n",
    "# Make uitls/nlp.ipynb avaible\n",
    "%run utils/nlp.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text 1 - 3, where 1 = Galileo, 2 = Mendel, 3 = Order\n",
    "df=load_text(3)\n",
    "\n",
    "text = df['text'][0]\n",
    "headline = df['headline'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = text #headline\n",
    "\n",
    "sentence_list = nltk.sent_tokenize(block)\n",
    "word_list = nltk.word_tokenize(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>You</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>seen</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>earlier</td>\n",
       "      <td>RBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>categories</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>like</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>species</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>genus</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Words  POS\n",
       "0         You  PRP\n",
       "1        have  VBP\n",
       "2        seen  VBN\n",
       "3     earlier  RBR\n",
       "4        that   IN\n",
       "5  categories  NNS\n",
       "6        like   IN\n",
       "7     species  NNS\n",
       "8           ,    ,\n",
       "9       genus   NN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagged = nltk.pos_tag(word_list)\n",
    "pd.DataFrame(pos_tagged, columns=['Words', 'POS'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK POS CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install python-crfsuite\n",
    "from nltk.tag import CRFTagger\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = treebank.tagged_sents()\n",
    "train_data = data[:3500]\n",
    "test_data = data[3500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CRFTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.train(train_data,'model.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_tagged = ct.tag(word_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ct.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9518830477296931\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun phrase chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = treebank_chunk.chunked_sents()\n",
    "train_data = data[:3000]\n",
    "test_data = data[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make defs in utils/np available\n",
    "%run utils/np.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train chunker model  \n",
    "ntc = NGramTagChunker(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate chunk model performance\n",
    "print(ntc.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ntc.parse(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 'DT'), ('key', 'JJ'), ('figure', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(tree[10][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngt = NGramTags(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = ngt.parse(pos_tagged)\n",
    "print(chunks[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galileo', 'NNP', 'B-NP'), ('Galilei', 'NNP', 'I-NP'), (',', ',', 'O'), ('born', 'VBN', 'O'), ('in', 'IN', 'O'), ('Pisa', 'NNP', 'B-NP'), (',', ',', 'O'), ('Italy', 'NNP', 'B-NP'), ('in', 'IN', 'O'), ('1564', 'CD', 'B-NP'), ('was', 'VBD', 'O'), ('a', 'DT', 'B-NP'), ('key', 'JJ', 'I-NP'), ('figure', 'NN', 'I-NP'), ('in', 'IN', 'O'), ('the', 'DT', 'B-NP'), ('scientiÔ¨Åc', 'JJ', 'I-NP'), ('revolution', 'NN', 'I-NP'), ('in', 'IN', 'O'), ('Europe', 'NNP', 'B-NP'), ('about', 'IN', 'O'), ('four', 'CD', 'B-NP'), ('centuries', 'NNS', 'I-NP'), ('ago', 'RB', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK NER tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_sent = [nltk.word_tokenize(s) for s in sentence_list]\n",
    "\n",
    "\n",
    "posed_sents = []\n",
    "\n",
    "for s in tok_sent:   \n",
    "\n",
    "    tmp = nltk.pos_tag(s)   \n",
    "\n",
    "    posed_sents.append(tmp) \n",
    "    \n",
    "\n",
    "ner = [nltk.chunk.ne_chunk(s) for s in pos_tagged_sents]\n",
    "\n",
    "ner[3].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'PRP', 'O'), ('thus', 'RB', 'O'), ('arrived', 'VBD', 'O'), ('at', 'IN', 'O'), ('the', 'DT', 'O'), ('law', 'NN', 'O'), ('of', 'IN', 'O'), ('inertia', 'NN', 'O'), ('that', 'WDT', 'O'), ('was', 'VBD', 'O'), ('the', 'DT', 'O'), ('starting', 'JJ', 'O'), ('point', 'NN', 'O'), ('of', 'IN', 'O'), ('the', 'DT', 'O'), ('subsequent', 'JJ', 'O'), ('epochal', 'NN', 'O'), ('work', 'NN', 'O'), ('of', 'IN', 'O'), ('Isaac', 'NNP', 'B-PERSON'), ('Newton', 'NNP', 'I-PERSON'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "iob_tags = tree2conlltags(ner[3])\n",
    "print(iob_tags)\n",
    "\n",
    "ne_tree = conlltags2tree(iob_tags)\n",
    "ne_tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
